# Configuration des modèles
models:
  led:
    model_name: "allenai/led-base-16384"
    max_input_length: 7168
    max_output_length: 512
    batch_size: 1
    device: "cuda"
    generation_config:
      num_beams: 2
      max_length: 512
      min_length: 100
      length_penalty: 2.0
      early_stopping: true
      no_repeat_ngram_size: 3
  
  openai:
    model_name: "gpt-4"
    fallback_model: "gpt-3.5-turbo"
    max_tokens: 500
    temperature: 0.3
    
  ner:
    model_name: "fr_core_news_sm"
    entities: ["PERSON", "ORG", "GPE", "DATE", "MONEY"]

# Configuration d'entraînement
training:
  num_epochs: 3
  learning_rate: 5e-5
  weight_decay: 0.01
  warmup_steps: 500
  fp16: true
  gradient_accumulation_steps: 4
  save_steps: 500
  eval_steps: 500
  logging_steps: 250
  save_total_limit: 2

# Longueurs de résumé
summary_lengths:
  short:
    min_length: 50
    max_length: 150
    target_length: 100
  long:
    min_length: 200
    max_length: 500
    target_length: 350