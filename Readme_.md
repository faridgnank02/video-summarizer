# ğŸ¥ Video Summarizer - Outil Professionnel de RÃ©sumÃ© VidÃ©o

Un outil avancÃ© de rÃ©sumÃ© de vidÃ©os utilisant l'intelligence artificielle, dÃ©veloppÃ© Ã  partir d'un notebook de fine-tuning LED et transformÃ© en application complÃ¨te.

## ğŸš€ FonctionnalitÃ©s

- **ğŸ“¹ Multi-sources** : YouTube, fichiers vidÃ©o locaux, texte direct
- **ğŸ¤– Dual Models** : LED fine-tunÃ© (qualitÃ©) + OpenAI GPT (rapiditÃ©)
- **ğŸ“ Longueurs flexibles** : RÃ©sumÃ©s courts (50-200 mots) ou longs (200-500 mots)
- **ğŸŒ Multi-langues** : FranÃ§ais et anglais avec dÃ©tection automatique
- **ğŸ” Named Entity Recognition** : Extraction automatique d'entitÃ©s
- **ğŸ“Š Monitoring** : MÃ©triques ROUGE, temps de traitement, coÃ»ts
- **ğŸ¨ Interface moderne** : Streamlit avec design professionnel
- **âš¡ API REST** : FastAPI pour intÃ©grations

## ğŸ“‹ Architecture

```
video-summarizer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                    # Ingestion et prÃ©processing
â”‚   â”‚   â”œâ”€â”€ ingestion.py         # YouTube, fichiers locaux
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Nettoyage, segmentation
â”‚   â”‚   â””â”€â”€ datasets.py          # Gestion datasets
â”‚   â”œâ”€â”€ models/                  # ModÃ¨les de ML
â”‚   â”‚   â”œâ”€â”€ led_model.py         # ModÃ¨le LED fine-tunÃ©
â”‚   â”‚   â”œâ”€â”€ openai_model.py      # ModÃ¨le OpenAI GPT
â”‚   â”‚   â”œâ”€â”€ ner_model.py         # Named Entity Recognition
â”‚   â”‚   â””â”€â”€ model_manager.py     # Orchestration modÃ¨les
â”‚   â”œâ”€â”€ training/                # EntraÃ®nement
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Fine-tuning LED
â”‚   â”‚   â””â”€â”€ evaluation.py        # MÃ©triques ROUGE
â”‚   â”œâ”€â”€ api/                     # API REST
â”‚   â”‚   â”œâ”€â”€ summarization.py     # Endpoints rÃ©sumÃ©
â”‚   â”‚   â””â”€â”€ video_processing.py  # Traitement vidÃ©o
â”‚   â”œâ”€â”€ monitoring/              # Monitoring
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Collecte mÃ©triques
â”‚   â”‚   â””â”€â”€ logging.py           # SystÃ¨me logs
â”‚   â””â”€â”€ ui/                      # Interface utilisateur
â”‚       â”œâ”€â”€ streamlit_app.py     # Application Streamlit
â”‚       â””â”€â”€ components/          # Composants UI
â”œâ”€â”€ config/                      # Configuration
â”‚   â”œâ”€â”€ model_config.yaml        # Config modÃ¨les
â”‚   â””â”€â”€ app_config.yaml          # Config application
â”œâ”€â”€ models/                      # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ data/                        # DonnÃ©es d'entraÃ®nement
â””â”€â”€ requirements.txt             # DÃ©pendances
```

## ğŸ› ï¸ Installation

### 1. Cloner et configurer l'environnement

```bash
cd /path/to/video-summarizer
source video-summarizer-env/bin/activate  # Environnement dÃ©jÃ  crÃ©Ã©
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Configurer les variables d'environnement

```bash
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API
```

Variables requises :
- `OPENAI_API_KEY` : ClÃ© API OpenAI (pour le modÃ¨le rapide)
- `WANDB_API_KEY` : Weights & Biases (optionnel, pour le monitoring)

### 4. TÃ©lÃ©charger les modÃ¨les spaCy (pour NER)

```bash
python -m spacy download fr_core_news_sm
python -m spacy download en_core_web_sm
```

## ğŸš€ Utilisation

### Interface Streamlit (RecommandÃ©)

```bash
streamlit run src/ui/streamlit_app.py
```

AccÃ©dez Ã  `http://localhost:8501`

### API REST

```bash
uvicorn src.api.summarization:app --reload
```

Documentation API : `http://localhost:8000/docs`

### Utilisation programmatique

```python
from src.models.model_manager import ModelManager

# Initialiser le gestionnaire
manager = ModelManager()

# RÃ©sumÃ© automatique (modÃ¨le recommandÃ©)
summary = manager.summarize_simple(
    text="Votre texte ici...",
    model_type="auto",  # ou "led", "openai"
    summary_length="long"  # ou "short"
)

print(summary)
```

## ğŸ¤– ModÃ¨les Disponibles

### LED Fine-tunÃ© (QualitÃ©)
- **Avantages** : QualitÃ© Ã©levÃ©e, comprÃ©hension contextuelle, spÃ©cialisÃ© pour longs textes
- **InconvÃ©nients** : Plus lent (~5-10s), nÃ©cessite GPU pour de meilleures performances
- **Usage** : RÃ©sumÃ©s de haute qualitÃ©, documents longs

### OpenAI GPT (RapiditÃ©)
- **Avantages** : TrÃ¨s rapide (~2-3s), qualitÃ© excellente, multi-langues natif
- **InconvÃ©nients** : CoÃ»t par utilisation, dÃ©pendance API externe
- **Usage** : RÃ©sumÃ©s rapides, prototypage, production lÃ©gÃ¨re

## ğŸ“Š Monitoring et MÃ©triques

### MÃ©triques collectÃ©es
- **ROUGE-1, ROUGE-2, ROUGE-L** : QualitÃ© des rÃ©sumÃ©s
- **Temps de traitement** : Performance des modÃ¨les
- **CoÃ»ts** : Utilisation API OpenAI
- **Taux d'erreur** : FiabilitÃ© du systÃ¨me

### Visualisation
- Dashboard Streamlit intÃ©grÃ©
- Export des mÃ©triques
- Comparaison des modÃ¨les

## ğŸ”§ Configuration

### ModÃ¨les (`config/model_config.yaml`)

```yaml
models:
  led:
    model_name: "allenai/led-base-16384"
    max_input_length: 7168
    max_output_length: 512
    generation_config:
      num_beams: 2
      length_penalty: 2.0
  
  openai:
    model_name: "gpt-4"
    fallback_model: "gpt-3.5-turbo"
    temperature: 0.3

summary_lengths:
  short:
    min_length: 50
    max_length: 200
  long:
    min_length: 200
    max_length: 500
```

### Application (`config/app_config.yaml`)

```yaml
ui:
  title: "ğŸ¥ RÃ©sumeur de VidÃ©os IA"
  max_file_size: 500  # MB
  supported_formats: ["mp4", "avi", "mov", "mkv"]

monitoring:
  enable_mlflow: true
  mlflow_uri: "sqlite:///mlflow.db"
```

## ğŸ“ˆ Fine-tuning du modÃ¨le LED

### PrÃ©parer les donnÃ©es

```python
from src.training.trainer import LEDTrainer

trainer = LEDTrainer()
trainer.prepare_data(
    dataset_name="potsawee/podcast_summary_assessment",
    sample_size=1000
)
```

### Lancer l'entraÃ®nement

```python
trainer.train(
    num_epochs=3,
    batch_size=1,
    learning_rate=5e-5
)
```

### Ã‰valuer le modÃ¨le

```python
from src.training.evaluation import ModelEvaluator

evaluator = ModelEvaluator()
metrics = evaluator.evaluate_model(
    model_path="./models/led_finetuned",
    test_data=test_dataset
)
```

## ğŸ¨ Interface Utilisateur

### FonctionnalitÃ©s UI
- **Upload vidÃ©os** : Drag & drop, support multi-formats
- **URLs YouTube** : Extraction automatique de transcripts
- **SÃ©lection modÃ¨le** : Choix entre qualitÃ© et rapiditÃ©
- **Longueur rÃ©sumÃ©** : Court ou long
- **EntitÃ©s nommÃ©es** : Mise en Ã©vidence automatique
- **Export** : PDF, TXT, JSON
- **Historique** : Sauvegarde des rÃ©sumÃ©s

### Composants
- Barre de progression en temps rÃ©el
- MÃ©triques de qualitÃ©
- Comparaison de modÃ¨les
- Visualisation des entitÃ©s

## ğŸ” Named Entity Recognition

```python
from src.models.ner_model import NERExtractor

ner = NERExtractor()
entities = ner.extract_entities(text)

# RÃ©sultat : {
#   "PERSON": ["John Doe", "Marie Dupont"],
#   "ORG": ["Google", "Microsoft"],
#   "GPE": ["Paris", "New York"]
# }
```

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/

# Tests de modÃ¨les
python -m pytest tests/test_models.py -v

# Tests d'intÃ©gration
python -m pytest tests/test_integration.py -v
```

## ğŸš€ DÃ©ploiement

### Docker

```bash
# Construire l'image
docker build -t video-summarizer .

# Lancer le conteneur
docker run -p 8501:8501 -p 8000:8000 video-summarizer
```

### Docker Compose

```bash
docker-compose up -d
```

## ğŸ“ Changelog

### Version 1.0.0
- âœ… Architecture modulaire complÃ¨te
- âœ… Dual models (LED + OpenAI)
- âœ… Interface Streamlit avancÃ©e
- âœ… API REST avec FastAPI
- âœ… Monitoring et mÃ©triques
- âœ… Named Entity Recognition
- âœ… Multi-langues (FR/EN)
- âœ… Configuration flexible

## ğŸ¤ Contribution

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changes (`git commit -am 'Ajouter nouvelle fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©er une Pull Request

## ğŸ“„ Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

- **Issues** : [GitHub Issues](https://github.com/votre-username/video-summarizer/issues)
- **Documentation** : [Wiki du projet](https://github.com/votre-username/video-summarizer/wiki)
- **Email** : votre.email@example.com

## ğŸ™ Remerciements

- ModÃ¨le LED original : [allenai/led-base-16384](https://huggingface.co/allenai/led-base-16384)
- Dataset : [potsawee/podcast_summary_assessment](https://huggingface.co/datasets/potsawee/podcast_summary_assessment)
- OpenAI pour l'API GPT
- CommunautÃ© Hugging Face

---

**DÃ©veloppÃ© avec â¤ï¸ pour dÃ©mocratiser l'accÃ¨s au rÃ©sumÃ© automatique de vidÃ©os**